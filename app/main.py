#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import hashlib
import json
import pickle
import logging
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
from googleapiclient.discovery import build
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from google.auth.exceptions import RefreshError
from ics import Calendar
from ics.event import Event
import config as config  # å¼•ç”¨è¨­å®šæª”

# åˆå§‹åŒ– logging
logging.basicConfig(
    filename=config.LOG_FILE,
    level=getattr(logging, config.LOG_LEVEL.upper(), "INFO"),
    format="%(asctime)s - %(levelname)s - %(message)s"
)

# æ–°å¢ StreamHandler å°‡ log è¼¸å‡ºåˆ°çµ‚ç«¯æ©Ÿ
# console_handler = logging.StreamHandler()
# console_handler.setLevel(getattr(logging, config.LOG_LEVEL.upper(), "INFO"))
# console_formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
# console_handler.setFormatter(console_formatter)
# logging.getLogger().addHandler(console_handler)

# ---------- HASH / SYNC RECORD ----------
def compute_event_hash(event):
    logging.debug("è¨ˆç®—äº‹ä»¶çš„ hash å€¼")
    
    # ç²å– rrule çš„å®‰å…¨æ–¹å¼
    rrule_value = None
    if hasattr(event, 'extra'):
        if isinstance(event.extra, dict):
            rrule_value = event.extra.get('rrule')
        elif hasattr(event.extra, 'rrule'):
            rrule_value = event.extra.rrule
    
    content = json.dumps({
        'summary': event.name,
        # ç§»é™¤ description æ¬„ä½
        'location': event.location,
        'start': str(event.begin),
        'end': str(event.end),
        'rrule': rrule_value
    }, sort_keys=True, ensure_ascii=False)
    return hashlib.md5(content.encode("utf-8")).hexdigest()

def get_sync_record_path(calendar_id):
    record_path = os.path.join(config.DATA_PATH, f"last_synced_{calendar_id.replace('@', '_').replace('.', '_')}.json")
    return record_path

def load_last_sync(calendar_id):
    path = get_sync_record_path(calendar_id)
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def save_last_sync(sync_data, calendar_id):
    path = get_sync_record_path(calendar_id)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(sync_data, f, ensure_ascii=False, indent=2)

# ---------- AUTH ----------
def get_credentials():
    creds = None
    if os.path.exists(config.TOKEN_FILE):
        with open(config.TOKEN_FILE, 'rb') as token:
            creds = pickle.load(token)

    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            try:
                creds.refresh(Request())
            except RefreshError:
                creds = _get_new_credentials()
        else:
            creds = _get_new_credentials()

        with open(config.TOKEN_FILE, 'wb') as token:
            pickle.dump(creds, token)

    return creds

def _get_new_credentials():
    if os.path.exists(config.CREDENTIALS_FILE):
        flow = InstalledAppFlow.from_client_secrets_file(config.CREDENTIALS_FILE, config.SCOPES)
        return flow.run_local_server(port=0)
    else:
        raise FileNotFoundError(f"éœ€è¦ {config.CREDENTIALS_FILE} æ–‡ä»¶ä¾†ç²å–æ–°æ†‘è­‰")

# ---------- PARSING ----------
def get_events_from_json(json_file):
    with open(json_file, 'r', encoding='utf-8') as f:
        events_data = json.load(f)
    valid_events = []
    
    for event_data in events_data:
        try:
            # æª¢æŸ¥æ˜¯å¦ç‚ºå­—å…¸ä¸¦åŒ…å«å¿…è¦æ¬„ä½
            if not isinstance(event_data, dict):
                logging.warning(f"è·³ééå­—å…¸æ ¼å¼äº‹ä»¶: {event_data}")
                continue
                
            # æª¢æŸ¥å¿…è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
            if 'begin' not in event_data or 'end' not in event_data or 'name' not in event_data:
                logging.warning(f"è·³éç¼ºå°‘å¿…è¦æ¬„ä½çš„äº‹ä»¶: {event_data}")
                continue
                
            event = Event()
            event.name = event_data.get('name', 'æœªå‘½åäº‹ä»¶')
            event.uid = event_data.get('uid', '')
            event.begin = datetime.fromisoformat(event_data.get('begin', '').replace('Z', '+00:00'))
            event.end = datetime.fromisoformat(event_data.get('end', '').replace('Z', '+00:00'))
            event.description = event_data.get('description')
            event.location = event_data.get('location')
            
            # è™•ç†é€±æœŸæ€§è¦å‰‡
            if 'recurrence_rules' in event_data and event_data['recurrence_rules']:
                rrule_str = event_data['recurrence_rules']
                if isinstance(rrule_str, str) and rrule_str.strip():
                    if not hasattr(event, 'extra') or not isinstance(event.extra, dict):
                        event.extra = {}
                    if not rrule_str.startswith('RRULE:'):
                        rrule_str = f"RRULE:{rrule_str}"
                    event.extra['rrule'] = [rrule_str]
            
            # è™•ç†ä¾‹å¤–æ—¥æœŸ
            if 'exdate' in event_data and event_data['exdate']:
                exdate_str = event_data['exdate']
                if not hasattr(event, 'extra'):
                    event.extra = {}
                event.extra['exdate'] = exdate_str
                
            valid_events.append(event)
        except Exception as e:
            logging.warning(f"è§£æäº‹ä»¶å¤±æ•—: {e}, äº‹ä»¶è³‡æ–™: {event_data}")
    
    # å‰µå»ºæ–°çš„ Calendar ç‰©ä»¶ä¸¦æ·»åŠ æ‰€æœ‰æœ‰æ•ˆäº‹ä»¶
    new_calendar = Calendar()
    for event in valid_events:
        new_calendar.events.add(event)
    
    return new_calendar

# ---------- GOOGLE EVENT FORMAT ----------
def convert_ics_to_google_event(ics_event):
    google_event = {
        'summary': ics_event.name,
    }
    if ics_event.description:
        google_event['description'] = ics_event.description
    if ics_event.location:
        google_event['location'] = ics_event.location

    tz = ZoneInfo(config.TIMEZONE)
    start_dt = ics_event.begin.replace(tzinfo=tz).astimezone(tz)
    end_dt = ics_event.end.replace(tzinfo=tz).astimezone(tz)

    if start_dt.time() == datetime.min.time() and end_dt.time() == datetime.min.time():
        google_event['start'] = {'date': start_dt.date().isoformat()}
        google_event['end'] = {'date': end_dt.date().isoformat()}
    else:
        google_event['start'] = {'dateTime': start_dt.isoformat(), 'timeZone': config.TIMEZONE}
        google_event['end'] = {'dateTime': end_dt.isoformat(), 'timeZone': config.TIMEZONE}

    if hasattr(ics_event, 'extra') and isinstance(ics_event.extra, dict):
        rrule_val = ics_event.extra.get('rrule')
        if isinstance(rrule_val, list) and rrule_val:
            rrule_str = rrule_val[0].strip()
            if not rrule_str.startswith("RRULE:"):
                rrule_str = f"RRULE:{rrule_str}"
            google_event['recurrence'] = [rrule_str]

    # è™•ç†ä¾‹å¤–æ—¥æœŸ - ä¿®æ”¹é€™éƒ¨åˆ†
    if hasattr(ics_event, 'extra'):
        # æ·»åŠ èª¿è©¦æ—¥èªŒ
        logging.debug(f"è™•ç†äº‹ä»¶ä¾‹å¤–æ—¥æœŸ: {ics_event.name}, extra é¡å‹: {type(ics_event.extra)}")
        
        # ç•¶ extra æ˜¯å­—å…¸æ™‚
        if isinstance(ics_event.extra, dict) and 'exdate' in ics_event.extra:
            if "recurrence" not in google_event:
                google_event["recurrence"] = []
            
            exdates = ics_event.extra['exdate'].split(",")
            for exdate in exdates:
                # æ¸…ç†æ ¼å¼ä½†ä¿ç•™åŸå§‹æ™‚é–“
                exdate_cleaned = exdate.replace("Z", "").replace("+00:00", "")
                if "T" not in exdate_cleaned:
                    exdate_cleaned = f"{exdate_cleaned}T000000"
                
                # ä½¿ç”¨æ­£ç¢ºçš„æ™‚å€æ ¼å¼
                google_event["recurrence"].append(f"EXDATE;TZID={config.TIMEZONE}:{exdate_cleaned}")
                logging.debug(f"æ·»åŠ ä¾‹å¤–æ—¥æœŸ: {exdate} -> EXDATE;TZID={config.TIMEZONE}:{exdate_cleaned}")
        
        # ç•¶ extra æ˜¯ Container ç‰©ä»¶æ™‚
        elif hasattr(ics_event.extra, 'exdate'):
            if "recurrence" not in google_event:
                google_event["recurrence"] = []
            
            exdate_str = str(ics_event.extra.exdate)
            exdates = exdate_str.split(",")
            for exdate in exdates:
                exdate_cleaned = exdate.replace("Z", "").replace("+00:00", "")
                if "T" not in exdate_cleaned:
                    exdate_cleaned = f"{exdate_cleaned}T000000"
                
                google_event["recurrence"].append(f"EXDATE;TZID={config.TIMEZONE}:{exdate_cleaned}")
                logging.debug(f"æ·»åŠ ä¾‹å¤–æ—¥æœŸ (Container): {exdate} -> EXDATE;TZID={config.TIMEZONE}:{exdate_cleaned}")

    # è™•ç†é€±æœŸäº‹ä»¶çš„ä¾‹å¤– (æ™‚é–“è¢«ä¿®æ”¹çš„å¯¦ä¾‹)
    if hasattr(ics_event, 'is_recurrence_exception') and ics_event.is_recurrence_exception:
        # å¦‚æœé€™æ˜¯é€±æœŸäº‹ä»¶çš„ä¾‹å¤–ï¼Œæ·»åŠ  recurringEventId å±¬æ€§
        parent_id = hashlib.md5((calendar_id + '|' + 
                               (ics_event.uid or ics_event.name) + '|' + 
                               'recurring'
                               ).encode()).hexdigest()
        
        google_event['recurringEventId'] = parent_id
        google_event['originalStartTime'] = {
            'dateTime': ics_event.begin.replace(tzinfo=tz).isoformat(),
            'timeZone': config.TIMEZONE
        }
        
        logging.debug(f"è™•ç†é€±æœŸäº‹ä»¶ä¾‹å¤–: {ics_event.name}, åŸå§‹é–‹å§‹æ™‚é–“: {ics_event.recurrence_id}")

    # èª¿è©¦è¼¸å‡º
    if 'recurrence' in google_event:
        logging.debug(f"äº‹ä»¶ {ics_event.name} çš„å®Œæ•´ recurrence åƒæ•¸: {google_event['recurrence']}")

    return google_event

# ---------- SYNC ----------
def sync_to_google(json_file, calendar_id=config.DEFAULT_CALENDAR_ID):
    logging.info(f"é–‹å§‹åŒæ­¥ {json_file} è‡³ Google Calendar (Calendar ID: {calendar_id})")
    creds = get_credentials()
    service = build('calendar', 'v3', credentials=creds)

    try:
        calendar = get_events_from_json(json_file)
        google_events = service.events().list(
            calendarId=calendar_id,
            timeMin=(datetime.utcnow() - timedelta(days=365)).isoformat() + 'Z',
            timeMax=(datetime.utcnow() + timedelta(days=365)).isoformat() + 'Z',
            singleEvents=True,
            maxResults=2500,
            orderBy='startTime'
        ).execute().get('items', [])
 
        google_events_dict = {event.get('id'): event for event in google_events}
        last_sync = load_last_sync(calendar_id)
        new_sync = {}
        added, updated, skipped, deleted = 0, 0, 0, 0

        # åˆ†é–‹è™•ç†é€±æœŸäº‹ä»¶å’Œä¾‹å¤–äº‹ä»¶
        recurring_events = []
        exception_events = []
        
        for event in calendar.events:
            # ç¢ºä¿ event æ˜¯ Event ç‰©ä»¶
            if not isinstance(event, Event):
                logging.warning(f"è·³éé Event ç‰©ä»¶: {event}")
                continue

            # å®‰å…¨ç²å– rrule
            has_rrule = False
            rrule_value = None
            if hasattr(event, 'extra'):
                if isinstance(event.extra, dict) and 'rrule' in event.extra:
                    has_rrule = True
                    rrule_value = event.extra.get('rrule')
                elif hasattr(event.extra, 'rrule'):
                    has_rrule = True
                    rrule_value = event.extra.rrule
            
            # å°é€±æœŸäº‹ä»¶å’Œå–®æ¬¡äº‹ä»¶å€åˆ†è™•ç†
            event_date = event.begin.date().isoformat()  # ç²å–æ—¥æœŸéƒ¨åˆ†
            if has_rrule:
                # é€±æœŸäº‹ä»¶ - ä½¿ç”¨ UID ç”Ÿæˆä¸€è‡´çš„ ID
                event_id = hashlib.md5((calendar_id + '|' + 
                                      (event.uid or event.name) + '|' + 
                                      'recurring'
                                      ).encode()).hexdigest()
                recurring_events.append(event)
            elif hasattr(event, 'is_recurrence_exception'):
                exception_events.append(event)
            else:
                # å–®æ¬¡äº‹ä»¶ - ä½¿ç”¨ UID + æ—¥æœŸç”Ÿæˆ ID
                # ç›¸åŒ UID åœ¨ä¸åŒæ—¥æœŸæœƒæœ‰ä¸åŒ ID
                event_id = hashlib.md5((calendar_id + '|' + 
                                      (event.uid or event.name) + '|' + 
                                      event_date + '|' +
                                      str(event.begin.time())
                                      ).encode()).hexdigest()
                
                google_event = convert_ics_to_google_event(event)
                google_event['id'] = event_id
                event_hash = compute_event_hash(event)
                new_sync[event_id] = event_hash

                if last_sync.get(event_id) == event_hash:
                    skipped += 1
                    logging.info(f"ğŸŸ¡ è·³éæœªè®Šæ›´äº‹ä»¶: {google_event['summary']}")
                    continue

                # å¦‚æœäº‹ä»¶ ID å·²å­˜åœ¨ï¼Œå…ˆåˆªé™¤å†æ’å…¥
                if event_id in google_events_dict:
                    try:
                        service.events().delete(calendarId=calendar_id, eventId=event_id).execute()
                        logging.info(f"âŒ åˆªé™¤é‡è¤‡äº‹ä»¶: {google_event['summary']}")
                    except Exception as e:
                        logging.warning(f"âš ï¸ åˆªé™¤é‡è¤‡äº‹ä»¶å¤±æ•—: {e}")

                try:
                    service.events().insert(calendarId=calendar_id, body=google_event).execute()
                    added += 1
                    logging.info(f"ğŸ†• æ–°å¢äº‹ä»¶: {google_event['summary']}")
                except Exception as e:
                    logging.error(f"âš ï¸ æ’å…¥äº‹ä»¶å¤±æ•—: {e}")

        # å…ˆè™•ç†é€±æœŸäº‹ä»¶
        for event in recurring_events:
            # é€±æœŸäº‹ä»¶ - ä½¿ç”¨ UID ç”Ÿæˆä¸€è‡´çš„ ID
            event_id = hashlib.md5((calendar_id + '|' + 
                                  (event.uid or event.name) + '|' + 
                                  'recurring'
                                  ).encode()).hexdigest()
            
            google_event = convert_ics_to_google_event(event)
            google_event['id'] = event_id
            event_hash = compute_event_hash(event)
            new_sync[event_id] = event_hash

            if last_sync.get(event_id) == event_hash:
                skipped += 1
                logging.info(f"ğŸŸ¡ è·³éæœªè®Šæ›´äº‹ä»¶: {google_event['summary']}")
                continue

            # å¦‚æœäº‹ä»¶ ID å·²å­˜åœ¨ï¼Œå…ˆåˆªé™¤å†æ’å…¥
            if event_id in google_events_dict:
                try:
                    service.events().delete(calendarId=calendar_id, eventId=event_id).execute()
                    logging.info(f"âŒ åˆªé™¤é‡è¤‡äº‹ä»¶: {google_event['summary']}")
                except Exception as e:
                    logging.warning(f"âš ï¸ åˆªé™¤é‡è¤‡äº‹ä»¶å¤±æ•—: {e}")

            try:
                service.events().insert(calendarId=calendar_id, body=google_event).execute()
                added += 1
                logging.info(f"ğŸ†• æ–°å¢äº‹ä»¶: {google_event['summary']}")
            except Exception as e:
                logging.error(f"âš ï¸ æ’å…¥äº‹ä»¶å¤±æ•—: {e}")

        # å†è™•ç†ä¾‹å¤–äº‹ä»¶
        for event in exception_events:
            # ä¾‹å¤–äº‹ä»¶ - ä½¿ç”¨ UID + æ—¥æœŸç”Ÿæˆ ID
            event_id = hashlib.md5((calendar_id + '|' + 
                                  (event.uid or event.name) + '|' + 
                                  event.begin.date().isoformat()
                                  ).encode()).hexdigest()
            
            google_event = convert_ics_to_google_event(event)
            google_event['id'] = event_id
            event_hash = compute_event_hash(event)
            new_sync[event_id] = event_hash

            if last_sync.get(event_id) == event_hash:
                skipped += 1
                logging.info(f"ğŸŸ¡ è·³éæœªè®Šæ›´äº‹ä»¶: {google_event['summary']}")
                continue

            # å¦‚æœäº‹ä»¶ ID å·²å­˜åœ¨ï¼Œå…ˆåˆªé™¤å†æ’å…¥
            if event_id in google_events_dict:
                try:
                    service.events().delete(calendarId=calendar_id, eventId=event_id).execute()
                    logging.info(f"âŒ åˆªé™¤é‡è¤‡äº‹ä»¶: {google_event['summary']}")
                except Exception as e:
                    logging.warning(f"âš ï¸ åˆªé™¤é‡è¤‡äº‹ä»¶å¤±æ•—: {e}")

            try:
                service.events().insert(calendarId=calendar_id, body=google_event).execute()
                added += 1
                logging.info(f"ğŸ†• æ–°å¢äº‹ä»¶: {google_event['summary']}")
            except Exception as e:
                logging.error(f"âš ï¸ æ’å…¥äº‹ä»¶å¤±æ•—: {e}")

        # å„²å­˜åŒæ­¥ç´€éŒ„
        save_last_sync(new_sync, calendar_id)
        logging.info(f"âœ… åŒæ­¥å®Œæˆï¼šæ–°å¢ {added}ï¼Œæ›´æ–° {updated}ï¼Œè·³é {skipped}ï¼Œåˆªé™¤ {deleted}")
    except Exception as e:
        logging.error(f"åŒæ­¥éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

# ---------- MAIN ----------
if __name__ == "__main__":
    logging.info(f"é–‹å§‹åŒæ­¥ {config.DEFAULT_JSON_FILE} è‡³ Google Calendar...")
    sync_to_google(config.DEFAULT_JSON_FILE)
